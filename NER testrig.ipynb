{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e58dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import json\n",
    "import random\n",
    "\n",
    "def load_data(file):\n",
    "    data = []\n",
    "    with open(file, 'r', encoding=\"latin1\") as f:\n",
    "        for line in f:\n",
    "            line=json.loads(line)\n",
    "            if \"label\" in line:\n",
    "                line[\"entities\"] = line.pop(\"label\")\n",
    "            else:\n",
    "                line[\"entities\"] = []\n",
    "            tmp_ents = []\n",
    "            for e in line[\"entities\"]:\n",
    "                if e[2] in ['SKILL', 'SOFT-SKILL']:\n",
    "                    tmp_ents.append((e[0], e[1], e[2]))\n",
    "\n",
    "                line[\"entities\"] = tmp_ents\n",
    "                data.append((line[\"data\"], line[\"entities\"]))\n",
    "    return data\n",
    "\n",
    "def save_data(file, data):\n",
    "    with open (file, 'w', encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent =4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93be8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "def spacySave(training_data, train=True, test=False):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    db = DocBin()\n",
    "    for text, annotations in training_data:\n",
    "        doc = nlp(text)\n",
    "        ents = []\n",
    "        for start, end, label in annotations:\n",
    "            span = doc.char_span(start, end, label=label)\n",
    "            ents.append(span)\n",
    "        doc.ents = ents\n",
    "        db.add(doc)\n",
    "    if(train):\n",
    "        db.to_disk(\"./data/train.spacy\")\n",
    "    if(test):\n",
    "        db.to_disk(\"./data/test.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bc306e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DATA = load_data(\"data/train.jsonl\")\n",
    "spacySave(TRAIN_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c5f39ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATA = load_data(\"data/test.jsonl\")\n",
    "spacySave(TEST_DATA, train=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0443203a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ℹ Saving to output directory: output\n",
      "ℹ Using CPU\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16428/1342656073.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcli\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./config.cfg\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"./output\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"paths.train\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"./data/train.spacy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"paths.dev\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"./data/test.spacy\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\cli\\train.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(config_path, output_path, use_gpu, overrides)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivider\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initializing pipeline\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mshow_validation_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhint_fill\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_nlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_gpu\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_gpu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgood\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Initialized pipeline\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdivider\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training pipeline\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\training\\initialize.py\u001b[0m in \u001b[0;36minit_nlp\u001b[1;34m(config, use_gpu)\u001b[0m\n\u001b[0;32m     82\u001b[0m             )\n\u001b[0;32m     83\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m             \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtrain_corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Initialized pipeline components: {nlp.pipe_names}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;31m# Detect components with listeners that are not frozen consistently\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36minitialize\u001b[1;34m(self, get_examples, sgd)\u001b[0m\n\u001b[0;32m   1284\u001b[0m             \u001b[0mbefore_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1285\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1286\u001b[1;33m             init_vocab(\n\u001b[0m\u001b[0;32m   1287\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"vocab_data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlookups\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lookups\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mI\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"vectors\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1288\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\training\\initialize.py\u001b[0m in \u001b[0;36minit_vocab\u001b[1;34m(nlp, data, lookups, vectors)\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;31m# warn if source model vectors are not identical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m     \u001b[0msourced_vectors_hashes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_sourced_vectors_hashes\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mvectors_hash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhash\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"strings\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msourced_component\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msourced_vectors_hash\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msourced_vectors_hashes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvectors_hash\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0msourced_vectors_hash\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\vectors.pyx\u001b[0m in \u001b[0;36mspacy.vectors.Vectors.to_bytes\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mto_bytes\u001b[1;34m(getters, exclude)\u001b[0m\n\u001b[0;32m   1239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mto_bytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetters\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1241\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msrsly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsgpack_dumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgetters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\util.py\u001b[0m in \u001b[0;36mto_dict\u001b[1;34m(getters, exclude)\u001b[0m\n\u001b[0;32m   1257\u001b[0m         \u001b[1;31m# Split to support file names like meta.json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1259\u001b[1;33m             \u001b[0mserialized\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1260\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mserialized\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\vectors.pyx\u001b[0m in \u001b[0;36mspacy.vectors.Vectors.to_bytes.serialize_weights\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\srsly\\_msgpack_api.py\u001b[0m in \u001b[0;36mmsgpack_dumps\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mserialized\u001b[0m \u001b[0mbytes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \"\"\"\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmsgpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_bin_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from spacy.cli.train import train\n",
    "train(\"./config.cfg\", \"./output\", overrides={\"paths.train\": \"./data/train.spacy\", \"paths.dev\": \"./data/test.spacy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7defd70",
   "metadata": {},
   "source": [
    "# THIS DID NOT WORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78007955",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spacy(TRAIN_DATA, iterations):\n",
    "    nlp = spacy.blank(\"en\")\n",
    "    #ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "    #skill_pattern_path = \"jz_skill_patterns.jsonl\"\n",
    "    #ruler.from_disk(skill_pattern_path)\n",
    "    ner = nlp.add_pipe(\"ner\", name=\"skills_ner\")\n",
    "    ner.add_label(\"SKILL\")\n",
    "    ner.add_label(\"SOFT-SKILL\")\n",
    "    other_pipes = [pipes for pipe in nlp.pipe_names if pipe !=\"skills_ner\"]\n",
    "    with nlp.disable_pipes(other_pipes):\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(iterations):\n",
    "            print(f\"Starting iteration {(str(itn))}\")\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            for text, annotations in TRAIN_DATA:\n",
    "                print(text)\n",
    "                nlp.update([text],\n",
    "                           [annotations], \n",
    "                           drop=0.2, \n",
    "                           sgd=optimizer, \n",
    "                           losses=losses\n",
    "                )\n",
    "            print(losses)\n",
    "    return(nlp)\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
